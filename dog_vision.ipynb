{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HkgCory/Tensorflow-deeplearning-colab-dog_breed/blob/main/dog_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "xV0tC_ki6PCb"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !unzip '/content/drive/MyDrive/deepLearning-dog/dog-breed-identification.zip' -d '/content/drive/MyDrive/deepLearning-dog/'"
      ],
      "metadata": {
        "id": "fY3F195U97NH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# end to end multiclass dog breed classification\n",
        "\n",
        "This notebook builds an end to end multi class image classification using tensorflow 2.0 and tensorflow hub\n",
        "\n",
        "#1 problem\n",
        "identifying the breed of a dog given an image of a dog.\n",
        "\n",
        "When Im sitting at the ccafe and i take a photo of a dog, I want to know what breed of a dog it is\n",
        "\n",
        "#2 data.\n",
        "\n",
        "The data we're using is from Kaggle's dog breed identification competition. \n",
        "\n",
        "# 3. Evaluation\n",
        "\n",
        "The evaluation is a file with prediction probabilities for each dog breed of each test images.\n",
        "\n",
        "#4. features\n",
        "\n",
        "some information about the data:\n",
        "\n",
        "we'r dealing with images(unstructured data) so it's probably best we use deep learning / transfer learning. \n",
        "\n",
        "there are 120 breeds of dogs, this means there are 120 different classes.\n",
        "\n",
        "There are around 10000+ images in the training set.(these images have labels)\n",
        "\n",
        "There are around 10000+ images in the test set( these images have no labels, because we will want to predict them.\n"
      ],
      "metadata": {
        "id": "3QZK9ZCs_HOh"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "apxCRubX9mSj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Get our workspace ready\n",
        "\n"
      ],
      "metadata": {
        "id": "_o0OZy4eGPWt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print('TF version: ', tf.__version__)\n",
        "import tensorflow_hub as hub\n",
        "print('TF Hubversion: ', hub.__version__)\n",
        "# check for gpu\n",
        "print('gpu', 'available (yes!)' if tf.config.list_physical_devices('GPU') else 'not available')"
      ],
      "metadata": {
        "id": "tQlijTLP6Y3w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fad6c251-3e79-4b18-c0c9-4f6be5ced33b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version:  2.11.0\n",
            "TF Hubversion:  0.12.0\n",
            "gpu not available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "1EnZ8VrFGMSG"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Get our Data Ready\n",
        "\n",
        "With all machine learning models, our data has to be innumerical format. so we will have to convert the data first, turning the images into tensors (numerical representation). command m h to open keyboard preferences."
      ],
      "metadata": {
        "id": "z4Kc06RnJoWT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# checkout labels of our data\n",
        "\n",
        "labels_csv = pd.read_csv('/content/drive/MyDrive/deepLearning-dog/labels.csv')\n",
        "# print(labels_csv.describe())\n",
        "# print(labels_csv.head())"
      ],
      "metadata": {
        "id": "nc8Hcrm-6Zll",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "588c75e2-c83e-4cd4-9a6a-8865351da7e6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-cee67340d71a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# checkout labels of our data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlabels_csv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/deepLearning-dog/labels.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# print(labels_csv.describe())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(labels_csv.head())\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m    223\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    700\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 702\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    703\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    704\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/deepLearning-dog/labels.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "0DKvygT49EVe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#how many images are there oof each breed?\n",
        "\n",
        "labels_csv['breed'].value_counts().plot.bar(figsize=(20,10))"
      ],
      "metadata": {
        "id": "ndcXXSNh6aRA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv['breed'].value_counts().median()"
      ],
      "metadata": {
        "id": "bwgHzWk96aaz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# view image\n",
        "from IPython.display import Image\n",
        "Image('/content/drive/MyDrive/deepLearning-dog/train/001513dfcb2ffafc82cccf4d8bbaba97.jpg')"
      ],
      "metadata": {
        "id": "30_CTIw16af-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting images and their labels\n",
        "\n",
        "lets get a list of all our image file pathname\n"
      ],
      "metadata": {
        "id": "vUPE6_WE6ajC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv.head()"
      ],
      "metadata": {
        "id": "o5mRaD71OQlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create pathnames from image ID\n",
        "filenames = ['/content/drive/MyDrive/deepLearning-dog/train/' + fname + '.jpg'for fname in labels_csv['id']]\n",
        "filenames[:10]"
      ],
      "metadata": {
        "id": "dDlkg6wo6amK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check whether number of filenames amtches number of actual image files\n",
        "\n",
        "import os\n",
        "if len(os.listdir('/content/drive/MyDrive/deepLearning-dog/train')) == len(filenames):\n",
        "  print('Filenames match actual amount of files!!! Proceed.')\n",
        "else:\n",
        "  print('Filenames do not match actual amount of files, check the target directory.')"
      ],
      "metadata": {
        "id": "U9ohCog-6ao3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Image(filenames[9000])"
      ],
      "metadata": {
        "id": "gCGuyDy3QIB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_csv['breed'][9000]"
      ],
      "metadata": {
        "id": "sZ9BLjjO6ars"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "now we have our training image filepath in a list, lets prepare labels\n"
      ],
      "metadata": {
        "id": "8nJbRe2U6auf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.array(labels_csv['breed'])\n",
        "labels\n"
      ],
      "metadata": {
        "id": "c_JOYiwu6axS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "metadata": {
        "id": "H2T9GEiI6a0O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#see if number of labels matches the nu,ber of filenames\n",
        "if len(labels) == len(filenames):\n",
        "  print('Number of labels amtches number of filenames!')\n",
        "else:\n",
        "  print('it doesnt match')"
      ],
      "metadata": {
        "id": "QfqnFQG06a27"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#find the unique label value\n",
        "unique_breeds = np.unique(labels)\n",
        "len(unique_breeds)"
      ],
      "metadata": {
        "id": "QgLVm4Uh6a5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Turn a single label into an array of booleans\n",
        "print(labels[0])\n",
        "labels[0] == unique_breeds"
      ],
      "metadata": {
        "id": "sXGvODeO6a8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#turn every label into a boolean array\n",
        "boolean_labels = [label == unique_breeds for label in labels]\n",
        "boolean_labels"
      ],
      "metadata": {
        "id": "fdyOctuq6a_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(boolean_labels)"
      ],
      "metadata": {
        "id": "rJBtTQKx6bLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# example: turning boolean array into integers\n",
        "\n",
        "print(labels[0])\n",
        "print(np.where(unique_breeds == labels[0]))\n",
        "print(boolean_labels[0].argmax())\n",
        "print(boolean_labels[0].astype(int))"
      ],
      "metadata": {
        "id": "S5zCbEvqFMPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating our own validation set\n",
        "\n",
        "Since the dataset from kaggle doesnt include validation set, we are going to create our own validation set."
      ],
      "metadata": {
        "id": "9DQGwpg8F3Qo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup X & y variables\n",
        "X = filenames\n",
        "y = boolean_labels"
      ],
      "metadata": {
        "id": "z0XwmHVuFMuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(filenames)"
      ],
      "metadata": {
        "id": "epWrLOk1HQcD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#We're going to start off experimenting with 1000 iamges and increase as needed.\n"
      ],
      "metadata": {
        "id": "sBP0HM1vFMwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# set number of images to use for experimenting \n",
        "NUM_IMAGES = 1000  #@param {type:'slider', min:1000, max:10000, steps:1000}"
      ],
      "metadata": {
        "id": "hCkPwwlAHclv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lets split our data into train and validation sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "# split them into training and validation of total size NUM_IMAGES\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES],\n",
        "                                                  y[:NUM_IMAGES],\n",
        "                                                  test_size=0.2,\n",
        "                                                  random_state=42)\n",
        "\n",
        "len(X_train), len(y_train), len(X_val), len(y_val)"
      ],
      "metadata": {
        "id": "eYYyKpHMICE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's have a geez at the training data\n",
        "X_train[:5], y_train[:2]"
      ],
      "metadata": {
        "id": "kBVkTZtaFMyX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing Images (turning images into Tensors)\n",
        "\n",
        "To preprocess our images into tensors we are going to write a function which does a few things:\n",
        "\n",
        "1. take an image filepath as input\n",
        "2. use tensorflow to read the file and save it to a variable, `image`\n",
        "3. Turn our `image` (a jpg) into Tensors\n",
        "4. Normalize our image (convert color channel values from 0-255 to 0-1).\n",
        "5. Resize the `image` to be a shape of(224, 224)\n",
        "6. Return the modified `image`"
      ],
      "metadata": {
        "id": "Qy_mMOelFM0J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert image to numpy array \n",
        "\n",
        "from matplotlib.pyplot import imread\n",
        "image = imread(filenames[42])\n",
        "image.shape"
      ],
      "metadata": {
        "id": "LVWWpL8fNMZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image.max(), image.min()"
      ],
      "metadata": {
        "id": "FIqgMprVFM1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#turn images into tensors\n",
        "tf.constant(image)[:3]\n"
      ],
      "metadata": {
        "id": "6ET4iDseFM3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.constant(imread(filenames[9000]))[:2]"
      ],
      "metadata": {
        "id": "OKJ9G2VjOcQM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define img size\n",
        "IMG_SIZE  = 224\n",
        "#create a function for preprocessing images\n",
        "\n",
        "def process_image(image_path, img_size = IMG_SIZE):\n",
        "\n",
        "  #take an image file path and turns the image into a tensor\n",
        "\n",
        "#read an image file\n",
        "  image = tf.io.read_file(image_path)\n",
        "# turn the image into numerical tensor with 3 color channels (RGB)\n",
        "  image = tf.image.decode_jpeg(image, channels = 3)\n",
        "# Convert the color channel values from 0-255 to 0-1 value\n",
        "  image = tf.image.convert_image_dtype(image, tf.float32)\n",
        "# Resize the iamge to our desired value (224, 224)\n",
        "  image = tf.image.resize(image, size = [IMG_SIZE, IMG_SIZE])\n",
        "\n",
        "  return image"
      ],
      "metadata": {
        "id": "peDGw5siFM5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = tf.io.read_file(filenames[26])\n",
        "tensor"
      ],
      "metadata": {
        "id": "UcsV9oHMX2Lt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.image.decode_jpeg(tensor, channels = 3)"
      ],
      "metadata": {
        "id": "3M_MuFxdFM80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Turning our data into batches\n",
        "\n",
        "Why turn our data into batches???\n",
        "\n",
        "\n",
        "\n",
        "let's say you're trying to process 10k+ images in one go... they all might not fit into memory.\n",
        "\n",
        "So that's why we do about 32 (this is batch size) images at a time ( you can manually adjust the batch size if need to be)\n",
        "\n",
        "In order to use TensorFlow effectively, we need our data in the form of Tensor tuples which look like this:\n",
        "`(image, label).\n",
        "\n"
      ],
      "metadata": {
        "id": "8mgMrydlFM-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create a simple function to return a tuple (image, label)\n",
        "def get_image_label(image_path, label):\n",
        "  \"\"\"\n",
        "    Takes an image file path name and the associated label,\n",
        "    processes the image and returns a tuple of (image,label).\n",
        "  \"\"\"\n",
        "  image = process_image(image_path)\n",
        "  return image,label"
      ],
      "metadata": {
        "id": "sjyaDVYlDBWD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# demo of the above\n",
        "(process_image(X[42],y[42]))[:2]"
      ],
      "metadata": {
        "id": "QqepzUGcFNAS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we've got a way to turn our data into tuples of Tensors in the form: `(image,label)`, let's make a function to turn all of our data (X & y) into batches"
      ],
      "metadata": {
        "id": "qafIFB6EFNCM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define the batch size, 32 is a good start\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "#create a function to turn data into batches\n",
        "\n",
        "def create_data_batches(X,y=None, batch_size=BATCH_SIZE, valid_data = False, test_data=False):\n",
        "  \"\"\"\n",
        "  Creates batches of data out of image(X) and label (y) pairs.\n",
        "  Shuffles the data if its training data but doesnt shuffle if its validation data.\n",
        "  Also accepts test data as input (no labels).\n",
        "    \"\"\"\n",
        "\n",
        "    # If the data is a test dataset, we probably don't have labels\n",
        "  if test_data:\n",
        "    print('Creating test data batches...')\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X))) #only filepaths (no labels)\n",
        "    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "    #if the data is a valid dataset, we dont need to shuffle it \n",
        "\n",
        "  elif valid_data:\n",
        "    print('Creating validation data batches...')\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X), tf.constant(y)))\n",
        "    data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n",
        "    return data_batch\n",
        "\n",
        "  else:\n",
        "    print('Creating training data batches')\n",
        "    # turn filepaths and labels into tensors\n",
        "\n",
        "    data = tf.data.Dataset.from_tensor_slices((tf.constant(X),tf.constant(y)))\n",
        "\n",
        "    # shuffling pathnames and labels before mapping image processor function is faster than shuffling\n",
        "    data = data.shuffle(buffer_size = len(X))\n",
        "    #create (image, label)tuples (this also turns the image path into a preprocess image)\n",
        "    data = data.map(get_image_label)\n",
        "    #Turn the training data into batches\n",
        "    data_batch = data.batch(BATCH_SIZE)\n",
        "\n",
        "  return data_batch\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fi95_5ovEQxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and validation data batches\n",
        "train_data = create_data_batches(X_train, y_train)\n",
        "val_data = create_data_batches(X_val, y_val, valid_data=True)"
      ],
      "metadata": {
        "id": "bDX68N89MGmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Checking out the different attributes of our data batches\n",
        "train_data.element_spec, val_data.element_spec"
      ],
      "metadata": {
        "id": "E9QDqHahNefx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y[0]"
      ],
      "metadata": {
        "id": "6FDEeVZCUSjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing data batches\n",
        "\n",
        "our data is now in batches, however, these can be a little hard to understand/comprehend, let's visualize the data batch"
      ],
      "metadata": {
        "id": "vj8ka34wFNDz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a function for viewing images in a data batch\n",
        "def show_25_images(images, labels):\n",
        "  \"\"\"\n",
        "  Displays a plot of 25 iamges and their labels from a data batch.\n",
        "  \"\"\"\n",
        "\n",
        "  #setup the figure\n",
        "  plt.figure(figsize=(10,10))\n",
        "  #loop through 25(for displaying 25 images)\n",
        "  for i in range(25):\n",
        "    #Create subplots (5 rows, 5 columns)\n",
        "    ax = plt.subplot(5,5, i+1)\n",
        "    #Display an image\n",
        "    plt.imshow(images[i])\n",
        "    # Add the iamge label as the title\n",
        "    plt.title(unique_breeds[labels[i].argmax()])\n",
        "    # Turn the grid lines off\n",
        "    plt.axis('off')"
      ],
      "metadata": {
        "id": "eYfSj1uGN6fq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "6MD-7YV_Phot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_images, train_labels = next(train_data.as_numpy_iterator())\n",
        "show_25_images(train_images, train_labels)"
      ],
      "metadata": {
        "id": "Omnozkc3PdDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_breeds[y[0].argmax()]"
      ],
      "metadata": {
        "id": "1jpcIgsxN7Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unique_breeds[train_labels[5].argmax()]"
      ],
      "metadata": {
        "id": "maZo_G9xY9Hh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's visualize the data in a training batch\n",
        "train_images, train_labels = next(train_data.as_numpy_iterator())\n",
        "show_25_images(train_images, train_labels)"
      ],
      "metadata": {
        "id": "PHitQ553N7NO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now let's visualize our validation set\n",
        "val_images, val_labels = next(val_data.as_numpy_iterator())\n",
        "show_25_images(val_images, val_labels)"
      ],
      "metadata": {
        "id": "Qy3ECSBkN7Pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# building a model\n",
        "\n",
        "before we build a model, there are a few things we need to define:\n",
        "* the input shape (our images shape, in the form of Tensors) to our model.\n",
        "* The output shape (image labels, in the form of Tensors) of our model\n",
        "* The URL of the model we want to use"
      ],
      "metadata": {
        "id": "MZD3u3LIN7Rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup input shape to the model\n",
        "\n",
        "INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3] #batch, height, width, color channels\n",
        "\n",
        "# setup output shape of our model\n",
        "OUTPUT_SHAPE = len(unique_breeds)\n",
        "\n",
        "# setup model URL from TensorFlow Hub\n",
        "\n",
        "MODEL_URL = "
      ],
      "metadata": {
        "id": "uPMkWuf0b2h4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3p1kpvXMN7Ts"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}